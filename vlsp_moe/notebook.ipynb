{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dd5dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f68d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/VLSP-2025-MedMT\n"
     ]
    }
   ],
   "source": [
    "cd VLSP-2025-MedMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5dbab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1yApcgWxgPrXFx_wHbjEUAw9YJFSocwbV\n",
      "From (redirected): https://drive.google.com/uc?id=1yApcgWxgPrXFx_wHbjEUAw9YJFSocwbV&confirm=t&uuid=9848d7e9-e9f6-4bae-aff3-2b1ae168f90a\n",
      "To: /kaggle/working/VLSP-2025-MedMT/train_data/train_data.csv\n",
      "100%|█████████████████████████████████████████| 163M/163M [00:00<00:00, 245MB/s]\n",
      "100%|█████████████████████████████████████████| 163M/163M [00:00<00:00, 245MB/s]\n"
     ]
    }
   ],
   "source": [
    "!./download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397702a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/VLSP-2025-MedMT/vlsp_moe/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ./vlsp_moe/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0fd830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted CSV to JSONL for MoE training.\n",
      "EN-VI samples: 500000\n",
      "VI-EN samples: 500000\n",
      "Combined samples: 1000000\n",
      "Created validation split:\n",
      "  Training samples: 900000\n",
      "  Validation samples: 100000\n",
      "  Expert distribution in validation set:\n",
      "    vi_en: 50010\n",
      "    en_vi: 49990\n"
     ]
    }
   ],
   "source": [
    "!python convert_csv_to_jsonl.py\n",
    "!python create_validation_split.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B configured with API key\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"cdc0cc2e33a9042de492b7891f33fad7d79b736d\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"vlsp-medmt\"\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "print(\"W&B configured with API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15969ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-22 02:59:20.108108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753153160.288585     105 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753153160.337758     105 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "✓ W&B API key set\n",
      "✓ W&B configured for project: vlsp-medmt\n",
      "✅ Using CUDA\n",
      "tokenizer_config.json: 9.73kB [00:00, 33.8MB/s]\n",
      "vocab.json: 2.78MB [00:00, 54.3MB/s]\n",
      "merges.txt: 1.67MB [00:00, 129MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 11.4M/11.4M [00:00<00:00, 23.7MB/s]\n",
      "config.json: 100%|█████████████████████████████| 726/726 [00:00<00:00, 7.22MB/s]\n",
      "model.safetensors.index.json: 25.6kB [00:00, 73.5MB/s]\n",
      "Fetching 2 files:   0%|                                   | 0/2 [00:00<?, ?it/s]\n",
      "model-00002-of-00002.safetensors:   0%|              | 0.00/622M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/3.44G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   0%|   | 68.9k/622M [00:00<1:44:27, 99.3kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 853k/3.44G [00:01<1:16:59, 745kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0%|    | 14.7M/3.44G [00:01<04:29, 12.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 28.6M/3.44G [00:01<02:37, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 32.2M/3.44G [00:02<03:00, 18.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1%|    | 37.5M/3.44G [00:02<02:42, 21.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   3%|▏    | 18.9M/622M [00:02<01:13, 8.16MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|    | 68.5M/3.44G [00:02<01:18, 43.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   2%|    | 82.5M/3.44G [00:02<01:01, 54.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 101M/3.44G [00:03<00:59, 56.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   3%|▏    | 111M/3.44G [00:03<01:03, 52.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 120M/3.44G [00:03<00:58, 56.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 130M/3.44G [00:03<00:58, 56.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   4%|▏    | 154M/3.44G [00:03<00:42, 76.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5%|▏    | 172M/3.44G [00:03<00:38, 85.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6%|▎     | 202M/3.44G [00:04<00:28, 115MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7%|▍     | 241M/3.44G [00:04<00:24, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8%|▍     | 276M/3.44G [00:04<00:20, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9%|▌     | 304M/3.44G [00:04<00:19, 158MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10%|▌     | 343M/3.44G [00:04<00:18, 164MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11%|▋     | 386M/3.44G [00:05<00:15, 193MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12%|▋     | 419M/3.44G [00:05<00:16, 181MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14%|▊     | 467M/3.44G [00:05<00:13, 227MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15%|▉     | 524M/3.44G [00:05<00:13, 216MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16%|▉     | 549M/3.44G [00:05<00:14, 194MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18%|█     | 603M/3.44G [00:05<00:11, 239MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19%|█     | 643M/3.44G [00:06<00:10, 268MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20%|█▏    | 700M/3.44G [00:06<00:09, 282MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21%|█▎    | 738M/3.44G [00:06<00:11, 243MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23%|█▎    | 775M/3.44G [00:06<00:10, 254MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24%|█▍    | 825M/3.44G [00:06<00:08, 300MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25%|█▌    | 863M/3.44G [00:06<00:08, 293MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26%|█▌    | 900M/3.44G [00:07<00:09, 256MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29%|█▋    | 986M/3.44G [00:07<00:07, 342MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30%|█▌   | 1.05G/3.44G [00:07<00:06, 362MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32%|█▌   | 1.11G/3.44G [00:07<00:06, 340MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33%|█▋   | 1.15G/3.44G [00:07<00:08, 277MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  14%|▋    | 86.0M/622M [00:07<00:46, 11.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35%|█▊   | 1.21G/3.44G [00:08<00:09, 231MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  25%|█▍    | 153M/622M [00:08<00:20, 22.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35%|██    | 220M/622M [00:08<00:10, 36.9MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46%|██▊   | 287M/622M [00:09<00:06, 55.5MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  57%|███▍  | 354M/622M [00:09<00:03, 76.1MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36%|█▍  | 1.25G/3.44G [00:09<00:22, 99.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37%|█▊   | 1.28G/3.44G [00:09<00:19, 108MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  68%|████  | 421M/622M [00:09<00:02, 92.4MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38%|█▉   | 1.31G/3.44G [00:09<00:20, 104MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  78%|█████▍ | 488M/622M [00:09<00:01, 123MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39%|█▉   | 1.36G/3.44G [00:10<00:16, 126MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41%|██   | 1.42G/3.44G [00:10<00:11, 172MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44%|██▏  | 1.51G/3.44G [00:10<00:09, 198MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46%|██▎  | 1.57G/3.44G [00:10<00:09, 193MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48%|██▍  | 1.67G/3.44G [00:11<00:06, 275MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52%|██▌  | 1.78G/3.44G [00:11<00:07, 222MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  89%|█████▎| 555M/622M [00:11<00:00, 67.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55%|██▊  | 1.89G/3.44G [00:12<00:07, 212MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59%|██▉  | 2.02G/3.44G [00:12<00:06, 204MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61%|███  | 2.09G/3.44G [00:13<00:06, 199MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62%|███  | 2.12G/3.44G [00:13<00:07, 166MB/s]\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64%|███▏ | 2.22G/3.44G [00:14<00:07, 175MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66%|███▎ | 2.28G/3.44G [00:14<00:09, 128MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70%|███▌ | 2.42G/3.44G [00:15<00:05, 198MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72%|███▌ | 2.46G/3.44G [00:15<00:06, 152MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73%|███▋ | 2.51G/3.44G [00:16<00:07, 119MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74%|███▋ | 2.56G/3.44G [00:17<00:08, 110MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76%|███▊ | 2.61G/3.44G [00:17<00:08, 101MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78%|███ | 2.67G/3.44G [00:18<00:08, 93.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79%|███▉ | 2.73G/3.44G [00:18<00:06, 105MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81%|████ | 2.79G/3.44G [00:19<00:05, 109MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83%|████▏| 2.84G/3.44G [00:19<00:05, 113MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84%|████▏| 2.89G/3.44G [00:19<00:04, 134MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85%|████▎| 2.94G/3.44G [00:20<00:03, 159MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|██████| 622M/622M [00:20<00:00, 30.5MB/s]\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:  87%|████▎| 3.00G/3.44G [00:20<00:02, 172MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89%|████▍| 3.07G/3.44G [00:20<00:01, 220MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91%|████▌| 3.13G/3.44G [00:20<00:01, 220MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93%|████▋| 3.19G/3.44G [00:21<00:01, 177MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96%|████▊| 3.32G/3.44G [00:21<00:00, 236MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100%|█████| 3.44G/3.44G [00:21<00:00, 157MB/s]\u001b[A\u001b[A\n",
      "Fetching 2 files: 100%|███████████████████████████| 2/2 [00:22<00:00, 11.06s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "generation_config.json: 100%|██████████████████| 239/239 [00:00<00:00, 1.86MB/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.20.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "  0%|                                                  | 0/3000 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/kaggle/working/VLSP-2025-MedMT/vlsp_moe/scripts/train_moe.py\", line 296, in <module>\n",
      "    train_moe_model()\n",
      "  File \"/kaggle/working/VLSP-2025-MedMT/vlsp_moe/scripts/train_moe.py\", line 287, in train_moe_model\n",
      "    trainer.train()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2240, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2555, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3745, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/kaggle/working/VLSP-2025-MedMT/vlsp_moe/scripts/train_moe.py\", line 186, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 818, in forward\n",
      "    return model_forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\", line 806, in __call__\n",
      "    return convert_to_fp32(self.model_forward(*args, **kwargs))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\", line 44, in decorate_autocast\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\", line 1757, in forward\n",
      "    return self.base_model(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\", line 193, in forward\n",
      "    return self.model.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 730, in forward\n",
      "    outputs: BaseModelOutputWithPast = self.model(\n",
      "                                       ^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 969, in wrapper\n",
      "    output = func(self, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 463, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\", line 48, in __call__\n",
      "    return super().__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 284, in forward\n",
      "    hidden_states, self_attn_weights = self.self_attn(\n",
      "                                       ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 235, in forward\n",
      "    attn_output, attn_weights = attention_interface(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/sdpa_attention.py\", line 54, in sdpa_attention_forward\n",
      "    attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 13.12 MiB is free. Process 6168 has 15.87 GiB memory in use. Of the allocated memory 15.58 GiB is allocated by PyTorch, and 8.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/VLSP-2025-MedMT/vlsp_moe/scripts/wandb/offline-run-20250722_030024-kspbi9cv\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250722_030024-kspbi9cv/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train_moe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd95f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
